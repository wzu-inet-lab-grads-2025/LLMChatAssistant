# Agentå·¥å…·æ”¹è¿›ææ¡ˆ

**åŸºäºv2.0è§„æ ¼çš„æ½œåœ¨ä¼˜åŒ–æ–¹å‘**
**ç”Ÿæˆæ—¶é—´**: 2025-12-31 08:30:00

---

## æ”¹è¿›1ï¼šå‘½ä»¤æ‰§è¡Œçš„å®æ—¶åé¦ˆå’Œå¼‚æ­¥æ”¯æŒ

### å½“å‰é—®é¢˜

**command_executor** å·¥å…·åŒæ­¥ç­‰å¾…å‘½ä»¤æ‰§è¡Œå®Œæ¯•ï¼š
- å¯¹äºçŸ­å‘½ä»¤ï¼ˆls, catï¼‰ï¼šæ­£å¸¸å·¥ä½œï¼Œè€—æ—¶ < 1ç§’
- å¯¹äºé•¿å‘½ä»¤ï¼ˆfind / -name "*.log", grep -r "error" /var/logï¼‰ï¼š
  - å¯èƒ½å¯¼è‡´ Agent å“åº”è¶…æ—¶
  - ç”¨æˆ·ç­‰å¾…æ—¶é—´è¿‡é•¿
  - æ— æ³•çœ‹åˆ°ä¸­é—´è¿›åº¦

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆAï¼šå¼‚æ­¥æ‰§è¡Œ + è½®è¯¢æœºåˆ¶ï¼ˆæ¨èï¼‰

```python
# src/tools/command_async.py
import asyncio
import subprocess
import uuid
from typing import Optional, Dict, Any
from src.tools.base import Tool, ToolExecutionResult

class AsyncCommandTool(Tool):
    """å¼‚æ­¥å‘½ä»¤æ‰§è¡Œå·¥å…·ï¼ˆæ”¯æŒé•¿æ—¶è¿è¡Œï¼‰"""

    name: str = "command_executor_async"
    description: str = """å¼‚æ­¥æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼ˆæ”¯æŒé•¿æ—¶è¿è¡Œå‘½ä»¤ï¼‰

    åŠŸèƒ½ï¼š
    1. æäº¤å‘½ä»¤åˆ°åå°æ‰§è¡Œ
    2. è¿”å›ä»»åŠ¡IDï¼Œæ”¯æŒåç»­æŸ¥è¯¢ç»“æœ
    3. æ”¯æŒå‘½ä»¤æ‰§è¡ŒçŠ¶æ€æŸ¥è¯¢
    4. è‡ªåŠ¨æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡

    é€‚ç”¨åœºæ™¯ï¼š
    - é•¿æ—¶è¿è¡Œå‘½ä»¤ï¼ˆfindã€grep -rã€tarç­‰ï¼‰
    - éœ€è¦æŸ¥è¯¢æ‰§è¡Œè¿›åº¦çš„åœºæ™¯

    å…³é”®è¯ï¼šæ‰§è¡Œã€è¿è¡Œã€åå°ã€å¼‚æ­¥
    """

    # ä»»åŠ¡å­˜å‚¨ï¼š{task_id: {process, stdout, stderr, status, start_time}}
    tasks: Dict[str, Dict[str, Any]] = {}
    MAX_TASKS = 100  # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    TASK_TIMEOUT = 300  # ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    def execute(self, command: str, args: Optional[list] = None,
                action: str = "run", task_id: str = None, **kwargs) -> ToolExecutionResult:
        """æ‰§è¡Œæˆ–æŸ¥è¯¢å‘½ä»¤"""

        if action == "run":
            return self._run_command_async(command, args)
        elif action == "status":
            return self._get_task_status(task_id)
        elif action == "cancel":
            return self._cancel_task(task_id)
        elif action == "result":
            return self._get_task_result(task_id)
        else:
            return ToolExecutionResult(
                success=False,
                error=f"ä¸æ”¯æŒçš„æ“ä½œ: {action}"
            )

    def _run_command_async(self, command: str, args: Optional[list]) -> ToolExecutionResult:
        """å¼‚æ­¥è¿è¡Œå‘½ä»¤"""
        # 1. éªŒè¯å‘½ä»¤ç™½åå•
        if command not in self.WHITELIST_COMMANDS:
            return ToolExecutionResult(
                success=False,
                error=f"å‘½ä»¤ä¸åœ¨ç™½åå•ä¸­: {command}"
            )

        # 2. éªŒè¯å‚æ•°å®‰å…¨æ€§
        if args:
            for arg in args:
                if any(char in str(arg) for char in self.BLACKLIST_CHARS):
                    return ToolExecutionResult(
                        success=False,
                        error=f"å‚æ•°åŒ…å«éæ³•å­—ç¬¦: {arg}"
                    )

        # 3. æ£€æŸ¥ä»»åŠ¡æ•°é‡é™åˆ¶
        if len(self.tasks) >= self.MAX_TASKS:
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡: {len(self.tasks)}/{self.MAX_TASKS}"
            )

        # 4. åˆ›å»ºä»»åŠ¡ID
        task_id = str(uuid.uuid4())[:8]

        # 5. å¯åŠ¨å¼‚æ­¥è¿›ç¨‹
        try:
            full_command = [command] + (args or [])
            process = subprocess.Popen(
                full_command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            # 6. è®°å½•ä»»åŠ¡
            self.tasks[task_id] = {
                "process": process,
                "command": ' '.join(full_command),
                "status": "running",
                "start_time": asyncio.get_event_loop().time(),
                "stdout": "",
                "stderr": ""
            }

            return ToolExecutionResult(
                success=True,
                output=json.dumps({
                    "task_id": task_id,
                    "status": "running",
                    "message": f"å‘½ä»¤å·²æäº¤åˆ°åå°æ‰§è¡Œï¼Œä»»åŠ¡ID: {task_id}",
                    "query_command": f"ä½¿ç”¨ action='status', task_id='{task_id}' æŸ¥è¯¢çŠ¶æ€"
                }, ensure_ascii=False),
                error=None
            )

        except Exception as e:
            return ToolExecutionResult(
                success=False,
                error=f"å¯åŠ¨å‘½ä»¤å¤±è´¥: {str(e)}"
            )

    def _get_task_status(self, task_id: str) -> ToolExecutionResult:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        if task_id not in self.tasks:
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"
            )

        task = self.tasks[task_id]
        process = task["process"]

        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å®Œæˆ
        poll_result = process.poll()

        if poll_result is None:
            # è¿›ç¨‹ä»åœ¨è¿è¡Œ
            elapsed = asyncio.get_event_loop().time() - task["start_time"]

            return ToolExecutionResult(
                success=True,
                output=json.dumps({
                    "task_id": task_id,
                    "status": "running",
                    "command": task["command"],
                    "elapsed_time": f"{elapsed:.1f}ç§’",
                    "message": "å‘½ä»¤æ­£åœ¨æ‰§è¡Œä¸­..."
                }, ensure_ascii=False),
                error=None
            )
        else:
            # è¿›ç¨‹å·²å®Œæˆ
            stdout, stderr = process.communicate()

            task["status"] = "completed"
            task["stdout"] = stdout
            task["stderr"] = stderr
            task["exit_code"] = poll_result

            return ToolExecutionResult(
                success=True,
                output=json.dumps({
                    "task_id": task_id,
                    "status": "completed",
                    "command": task["command"],
                    "exit_code": poll_result,
                    "elapsed_time": f"{asyncio.get_event_loop().time() - task['start_time']:.1f}ç§’",
                    "message": "å‘½ä»¤æ‰§è¡Œå®Œæˆ",
                    "query_result": f"ä½¿ç”¨ action='result', task_id='{task_id}' è·å–ç»“æœ"
                }, ensure_ascii=False),
                error=None
            )

    def _get_task_result(self, task_id: str) -> ToolExecutionResult:
        """è·å–ä»»åŠ¡ç»“æœ"""
        if task_id not in self.tasks:
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"
            )

        task = self.tasks[task_id]

        if task["status"] != "completed":
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡å°šæœªå®Œæˆ: {task_id} (çŠ¶æ€: {task['status']})"
            )

        return ToolExecutionResult(
            success=task["exit_code"] == 0,
            output=json.dumps({
                "task_id": task_id,
                "command": task["command"],
                "exit_code": task["exit_code"],
                "stdout": task["stdout"],
                "stderr": task["stderr"]
            }, ensure_ascii=False),
            error=task["stderr"] if task["exit_code"] != 0 else None
        )

    def _cancel_task(self, task_id: str) -> ToolExecutionResult:
        """å–æ¶ˆä»»åŠ¡"""
        if task_id not in self.tasks:
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}"
            )

        task = self.tasks[task_id]

        if task["status"] == "completed":
            return ToolExecutionResult(
                success=False,
                error=f"ä»»åŠ¡å·²å®Œæˆï¼Œæ— æ³•å–æ¶ˆ: {task_id}"
            )

        try:
            task["process"].kill()
            task["status"] = "cancelled"

            return ToolExecutionResult(
                success=True,
                output=json.dumps({
                    "task_id": task_id,
                    "status": "cancelled",
                    "message": "ä»»åŠ¡å·²å–æ¶ˆ"
                }, ensure_ascii=False),
                error=None
            )

        except Exception as e:
            return ToolExecutionResult(
                success=False,
                error=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}"
            )
```

#### ä½¿ç”¨åœºæ™¯

**åœºæ™¯1ï¼šæ‰§è¡Œé•¿æ—¶å‘½ä»¤**
```
ç”¨æˆ·: "åœ¨ç³»ç»Ÿä¸­æŸ¥æ‰¾æ‰€æœ‰æ—¥å¿—æ–‡ä»¶"
  â†“
Step 1: æäº¤å¼‚æ­¥å‘½ä»¤
TOOL: command_executor_async
ARGS: {
  "command": "find",
  "args": ["/", "-name", "*.log"],
  "action": "run"
}
  â†“
è¿”å›: {
  "task_id": "abc12345",
  "status": "running",
  "message": "å‘½ä»¤å·²æäº¤åˆ°åå°æ‰§è¡Œï¼Œä»»åŠ¡ID: abc12345"
}
  â†“
Agent: "å·²å¯åŠ¨æŸ¥æ‰¾ä»»åŠ¡ï¼ˆä»»åŠ¡ID: abc12345ï¼‰ï¼Œé¢„è®¡éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·ç¨åæŸ¥è¯¢ç»“æœ"

ç”¨æˆ·: "æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€"
  â†“
Step 2: æŸ¥è¯¢çŠ¶æ€
TOOL: command_executor_async
ARGS: {
  "action": "status",
  "task_id": "abc12345"
}
  â†“
è¿”å›: {
  "status": "running",
  "elapsed_time": "15.3ç§’",
  "message": "å‘½ä»¤æ­£åœ¨æ‰§è¡Œä¸­..."
}
  â†“
Agent: "ä»»åŠ¡æ­£åœ¨æ‰§è¡Œä¸­ï¼Œå·²è¿è¡Œ15.3ç§’"

ç”¨æˆ·: "è·å–ä»»åŠ¡ç»“æœ"
  â†“
Step 3: è·å–ç»“æœ
TOOL: command_executor_async
ARGS: {
  "action": "result",
  "task_id": "abc12345"
}
  â†“
è¿”å›: {
  "exit_code": 0,
  "stdout": "/var/log/app.log\n/var/log/system.log\n...",
  "stderr": ""
}
  â†“
Agent: "æ‰¾åˆ°ä»¥ä¸‹æ—¥å¿—æ–‡ä»¶ï¼š\n- /var/log/app.log\n- /var/log/system.log\n..."
```

#### æ–¹æ¡ˆBï¼šè¶…æ—¶åˆ†çº§ç­–ç•¥ï¼ˆç®€å•ï¼‰

```python
# src/tools/command.py
class CommandTool(Tool):
    """å‘½ä»¤æ‰§è¡Œå·¥å…·ï¼ˆè¶…æ—¶åˆ†çº§ï¼‰"""

    # æ ¹æ®å‘½ä»¤ç±»å‹è®¾ç½®ä¸åŒè¶…æ—¶
    COMMAND_TIMEOUTS = {
        'find': 120,      # findå‘½ä»¤ï¼š2åˆ†é’Ÿ
        'grep': 60,       # grepå‘½ä»¤ï¼š1åˆ†é’Ÿ
        'tar': 300,       # tarå‘½ä»¤ï¼š5åˆ†é’Ÿ
        'default': 30     # é»˜è®¤ï¼š30ç§’
    }

    def execute(self, command: str, args: Optional[list] = None,
                timeout: Optional[int] = None, **kwargs) -> ToolExecutionResult:
        """æ‰§è¡Œå‘½ä»¤ï¼ˆè‡ªåŠ¨è¶…æ—¶åˆ†çº§ï¼‰"""

        # 1. å¦‚æœæœªæŒ‡å®šè¶…æ—¶ï¼Œæ ¹æ®å‘½ä»¤ç±»å‹è‡ªåŠ¨è®¾ç½®
        if timeout is None:
            timeout = self.COMMAND_TIMEOUTS.get(
                command,
                self.COMMAND_TIMEOUTS['default']
            )

        # 2. æ‰§è¡Œå‘½ä»¤
        try:
            result = subprocess.run(
                [command] + (args or []),
                capture_output=True,
                text=True,
                timeout=timeout,
                check=False
            )

            return ToolExecutionResult(
                success=result.returncode == 0,
                output=result.stdout,
                error=result.stderr if result.returncode != 0 else None
            )

        except subprocess.TimeoutExpired:
            return ToolExecutionResult(
                success=False,
                error=f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰: {command}ã€‚"
                      f"å»ºè®®ä½¿ç”¨å¼‚æ­¥æ¨¡å¼: action='run'"
            )
```

### æ¨èæ–¹æ¡ˆ

- **çŸ­å‘½ä»¤**ï¼ˆls, cat, psï¼‰ï¼šä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼ˆæ–¹æ¡ˆBï¼‰
- **é•¿å‘½ä»¤**ï¼ˆfind, grep -r, tarï¼‰ï¼šä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬ï¼ˆæ–¹æ¡ˆAï¼‰

Agentå¯ä»¥æ ¹æ®å‘½ä»¤ç±»å‹è‡ªåŠ¨é€‰æ‹©ï¼š
```python
ASYNC_COMMANDS = {'find', 'grep', 'tar', 'dd'}

if command in ASYNC_COMMANDS:
    return command_executor_async.execute(command, args, action="run")
else:
    return command_executor.execute(command, args)
```

---

## æ”¹è¿›2ï¼šæ–‡ä»¶æ£€ç´¢çš„æ··åˆç­–ç•¥

### å½“å‰é—®é¢˜

**semantic_search** çº¯ç²¹ä¾èµ–å‘é‡æ£€ç´¢ï¼š
- **è¯­ä¹‰æŸ¥è¯¢**ï¼š"æ•°æ®åº“é…ç½®æ–‡ä»¶" â†’ å‘é‡æ£€ç´¢æ•ˆæœå¥½ âœ…
- **ç²¾ç¡®æ–‡ä»¶å**ï¼š"config.yaml" â†’ å‘é‡æ£€ç´¢å¯èƒ½è¿”å›ç›¸ä¼¼ä½†ä¸å®Œå…¨åŒ¹é…çš„ç»“æœ âŒ
- **æ¨¡ç³Šæ–‡ä»¶å**ï¼š"config" â†’ å¯èƒ½åŒ¹é…åˆ° config.yaml, config.json, config.yml

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆï¼šæ··åˆæ£€ç´¢ç­–ç•¥ï¼ˆKeyword + Semanticï¼‰

```python
# src/tools/semantic_search_v2.py
import re
import glob
import json
from typing import Optional, List, Tuple
from src.tools.base import Tool, ToolExecutionResult

class SemanticSearchToolV2(Tool):
    """æ··åˆæ£€ç´¢å·¥å…·ï¼ˆå…³é”®å­— + è¯­ä¹‰ï¼‰"""

    name: str = "semantic_search"
    description: str = """é€šè¿‡è‡ªç„¶è¯­è¨€æˆ–æ–‡ä»¶åæ£€ç´¢æ–‡ä»¶ï¼ˆæ··åˆç­–ç•¥ï¼‰

    æ£€ç´¢ç­–ç•¥ï¼š
    1. ç²¾ç¡®æ–‡ä»¶ååŒ¹é…ï¼ˆå¦‚ "config.yaml"ï¼‰
    2. æ¨¡ç³Šæ–‡ä»¶ååŒ¹é…ï¼ˆå¦‚ "config" â†’ config.yaml, config.jsonï¼‰
    3. è¯­ä¹‰æ£€ç´¢ï¼ˆå¦‚ "æ•°æ®åº“é…ç½®" â†’ READMEç›¸å…³ç« èŠ‚ï¼‰

    é€‚ç”¨åœºæ™¯ï¼š
    - "ä¸‹è½½ config.yaml" â†’ ç²¾ç¡®åŒ¹é…
    - "æŸ¥æ‰¾é…ç½®æ–‡ä»¶" â†’ æ¨¡ç³ŠåŒ¹é… + è¯­ä¹‰æ£€ç´¢
    - "æ•°æ®åº“é…ç½®åœ¨å“ªé‡Œ" â†’ è¯­ä¹‰æ£€ç´¢

    å…³é”®è¯ï¼šæœç´¢ã€æ£€ç´¢ã€æŸ¥æ‰¾ã€æ–‡æ¡£ã€æ–‡ä»¶
    """

    llm_provider: Optional[Any] = None
    vector_store: Optional[Any] = None
    index_manager: Optional[Any] = None
    search_paths: List[str] = ["/storage/uploads", "/home/project"]

    def execute(self, query: str, scope: str = "all",
                top_k: int = 3, **kwargs) -> ToolExecutionResult:
        """æ‰§è¡Œæ··åˆæ£€ç´¢"""

        # ç­–ç•¥1: ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
        if self._is_exact_filename(query):
            exact_results = self._search_exact_filename(query, scope)
            if exact_results:
                return ToolExecutionResult(
                    success=True,
                    output=json.dumps({
                        "strategy": "exact_match",
                        "total": len(exact_results),
                        "results": exact_results
                    }, ensure_ascii=False, indent=2),
                    error=None
                )

        # ç­–ç•¥2: æ¨¡ç³Šæ–‡ä»¶ååŒ¹é…
        fuzzy_results = self._search_fuzzy_filename(query, scope, top_k)

        # ç­–ç•¥3: è¯­ä¹‰æ£€ç´¢ï¼ˆä½œä¸ºè¡¥å……æˆ–å…œåº•ï¼‰
        semantic_results = self._search_semantic(query, scope, top_k)

        # åˆå¹¶ç»“æœï¼ˆå»é‡ï¼‰
        combined_results = self._merge_results(
            fuzzy_results,
            semantic_results,
            top_k
        )

        return ToolExecutionResult(
            success=True,
            output=json.dumps({
                "strategy": "hybrid",
                "total": len(combined_results),
                "results": combined_results
            }, ensure_ascii=False, indent=2),
            error=None
        )

    def _is_exact_filename(self, query: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç²¾ç¡®æ–‡ä»¶åæŸ¥è¯¢"""
        # ç‰¹å¾ï¼šåŒ…å«æ‰©å±•åï¼Œæ— ç©ºæ ¼
        pattern = r'^[\w\-\./]+\.(yaml|yml|json|xml|txt|md|py|js|log|pdf|png|jpg)$'
        return bool(re.match(pattern, query.strip(), re.IGNORECASE))

    def _search_exact_filename(self, query: str, scope: str) -> List[dict]:
        """ç²¾ç¡®æ–‡ä»¶ååŒ¹é…"""
        results = []
        filename = query.strip()

        # åœ¨ç´¢å¼•çš„æ–‡ä»¶ä¸­æœç´¢
        indexed_files = self.vector_store.list_files()

        for file_info in indexed_files:
            if file_info['filename'] == filename:
                # æ£€æŸ¥scopeè¿‡æ»¤
                if scope == "uploads" and not file_info['filepath'].startswith('/storage/uploads'):
                    continue
                if scope == "system" and file_info['filepath'].startswith('/storage/uploads'):
                    continue

                results.append({
                    "filename": file_info['filename'],
                    "filepath": file_info['filepath'],
                    "similarity": 1.0,  # ç²¾ç¡®åŒ¹é…
                    "match_type": "exact_filename"
                })

        return results

    def _search_fuzzy_filename(self, query: str, scope: str,
                               top_k: int) -> List[dict]:
        """æ¨¡ç³Šæ–‡ä»¶ååŒ¹é…"""
        results = []
        query_lower = query.lower().strip()

        # æå–æŸ¥è¯¢å…³é”®è¯ï¼ˆå»é™¤æ‰©å±•åï¼‰
        query_keywords = query_lower.replace('.', ' ').split()

        # åœ¨ç´¢å¼•çš„æ–‡ä»¶ä¸­æœç´¢
        indexed_files = self.vector_store.list_files()

        for file_info in indexed_files:
            # æ£€æŸ¥scopeè¿‡æ»¤
            if scope == "uploads" and not file_info['filepath'].startswith('/storage/uploads'):
                continue
            if scope == "system" and file_info['filepath'].startswith('/storage/uploads'):
                continue

            filename = file_info['filename'].lower()

            # è®¡ç®—åŒ¹é…åº¦
            match_score = 0.0

            # å…³é”®è¯åŒ¹é…ï¼ˆæ¯ä¸ªå…³é”®è¯0.3åˆ†ï¼‰
            for keyword in query_keywords:
                if keyword in filename:
                    match_score += 0.3

            # å‰ç¼€åŒ¹é…ï¼ˆ0.2åˆ†ï¼‰
            if filename.startswith(query_lower):
                match_score += 0.2

            # åŒ…å«å®Œæ•´æŸ¥è¯¢ï¼ˆ0.3åˆ†ï¼‰
            if query_lower in filename:
                match_score += 0.3

            # è‡³å°‘åŒ¹é…ä¸€ä¸ªå…³é”®è¯
            if match_score > 0:
                results.append({
                    "filename": file_info['filename'],
                    "filepath": file_info['filepath'],
                    "similarity": min(match_score, 1.0),
                    "match_type": "fuzzy_filename"
                })

        # æŒ‰åŒ¹é…åº¦æ’åº
        results.sort(key=lambda x: x['similarity'], reverse=True)

        return results[:top_k]

    def _search_semantic(self, query: str, scope: str,
                        top_k: int) -> List[dict]:
        """è¯­ä¹‰æ£€ç´¢ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        query_embedding = self._get_embedding(query)

        results = []
        if scope in ("all", "system"):
            results.extend(self._search_system_docs(query_embedding, top_k))

        if scope in ("all", "uploads"):
            results.extend(self._search_uploads(query_embedding, top_k))

        # æ ‡è®°åŒ¹é…ç±»å‹
        for result in results:
            result["match_type"] = "semantic"

        return results

    def _merge_results(self, fuzzy_results: List[dict],
                      semantic_results: List[dict],
                      top_k: int) -> List[dict]:
        """åˆå¹¶æ£€ç´¢ç»“æœï¼ˆå»é‡ï¼‰"""
        seen_paths = set()
        combined = []

        # ä¼˜å…ˆæ·»åŠ æ¨¡ç³ŠåŒ¹é…ç»“æœ
        for result in fuzzy_results:
            if result['filepath'] not in seen_paths:
                combined.append(result)
                seen_paths.add(result['filepath'])

        # è¡¥å……è¯­ä¹‰æ£€ç´¢ç»“æœ
        for result in semantic_results:
            if result['filepath'] not in seen_paths:
                combined.append(result)
                seen_paths.add(result['filepath'])

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        combined.sort(key=lambda x: x['similarity'], reverse=True)

        return combined[:top_k]

    def _get_embedding(self, query: str) -> List[float]:
        """è®¡ç®—æŸ¥è¯¢å‘é‡"""
        import asyncio
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(
            asyncio.ensure_future(self.llm_provider.embed([query]))
        )[0]
```

#### ä½¿ç”¨åœºæ™¯å¯¹æ¯”

**åœºæ™¯1ï¼šç²¾ç¡®æ–‡ä»¶å**
```
ç”¨æˆ·: "ä¸‹è½½ config.yaml"
  â†“
ç­–ç•¥1: ç²¾ç¡®åŒ¹é…
  â†’ æ‰¾åˆ°: /storage/uploads/abc123/config.yaml (similarity=1.0)
  â†“
è¿”å›: {
  "strategy": "exact_match",
  "results": [{
    "filename": "config.yaml",
    "filepath": "/storage/uploads/abc123/config.yaml",
    "similarity": 1.0,
    "match_type": "exact_filename"
  }]
}
```

**åœºæ™¯2ï¼šæ¨¡ç³Šæ–‡ä»¶å**
```
ç”¨æˆ·: "æŸ¥æ‰¾é…ç½®æ–‡ä»¶"
  â†“
ç­–ç•¥1: ç²¾ç¡®åŒ¹é… â†’ æœªå‘½ä¸­
  â†“
ç­–ç•¥2: æ¨¡ç³ŠåŒ¹é…
  â†’ æ‰¾åˆ°: config.yaml (0.8), config.json (0.8), config.yml (0.8)
  â†“
ç­–ç•¥3: è¯­ä¹‰æ£€ç´¢
  â†’ æ‰¾åˆ°: README.md (0.75) ä¸­æåˆ°é…ç½®
  â†“
è¿”å›: {
  "strategy": "hybrid",
  "results": [
    {"filename": "config.yaml", "similarity": 0.8, "match_type": "fuzzy_filename"},
    {"filename": "config.json", "similarity": 0.8, "match_type": "fuzzy_filename"},
    {"filename": "README.md", "similarity": 0.75, "match_type": "semantic"}
  ]
}
```

**åœºæ™¯3ï¼šçº¯è¯­ä¹‰æŸ¥è¯¢**
```
ç”¨æˆ·: "å¦‚ä½•é…ç½®æ•°æ®åº“ï¼Ÿ"
  â†“
ç­–ç•¥1: ç²¾ç¡®åŒ¹é… â†’ æœªå‘½ä¸­
  â†“
ç­–ç•¥2: æ¨¡ç³ŠåŒ¹é… â†’ æœªå‘½ä¸­
  â†“
ç­–ç•¥3: è¯­ä¹‰æ£€ç´¢
  â†’ æ‰¾åˆ°: README.md (0.92)
  â†“
è¿”å›: {
  "strategy": "hybrid",
  "results": [{
    "filename": "README.md",
    "similarity": 0.92,
    "match_type": "semantic",
    "chunk": "æ•°æ®åº“é…ç½®æ­¥éª¤ï¼š\n1. ç¼–è¾‘ config.yaml..."
  }]
}
```

### æ£€ç´¢ç­–ç•¥ä¼˜å…ˆçº§

| æŸ¥è¯¢ç±»å‹ | ç‰¹å¾ | ç­–ç•¥ä¼˜å…ˆçº§ |
|---------|------|-----------|
| ç²¾ç¡®æ–‡ä»¶å | "config.yaml" | 1. ç²¾ç¡®åŒ¹é… â†’ 2. è¿”å› |
| æ¨¡ç³Šæ–‡ä»¶å | "config" | 1. æ¨¡ç³ŠåŒ¹é… â†’ 2. è¯­ä¹‰è¡¥å…… |
| è¯­ä¹‰æŸ¥è¯¢ | "æ•°æ®åº“é…ç½®" | 1. è¯­ä¹‰æ£€ç´¢ |
| æ‰©å±•åæŸ¥è¯¢ | "*.log" | 1. Globæ¨¡å¼åŒ¹é… |

---

## æ”¹è¿›3ï¼šå‹å¥½çš„é”™è¯¯å¤„ç†å’Œè‡ªæˆ‘ä¿®æ­£

### å½“å‰é—®é¢˜

å·¥å…·æ‰§è¡Œå¤±è´¥æ—¶ï¼š
- ç›´æ¥è¿”å› Python å¼‚å¸¸ä¿¡æ¯
- Agent æ— æ³•è‡ªæˆ‘ä¿®æ­£
- ç”¨æˆ·ä½“éªŒå·®

### è§£å†³æ–¹æ¡ˆ

#### æ–¹æ¡ˆï¼šç»“æ„åŒ–é”™è¯¯ + è‡ªæˆ‘ä¿®æ­£æç¤º

```python
# src/tools/base.py
from enum import Enum

class ErrorType(Enum):
    """é”™è¯¯ç±»å‹æšä¸¾"""
    # å‚æ•°é”™è¯¯
    INVALID_PARAM = "INVALID_PARAM"
    MISSING_PARAM = "MISSING_PARAM"
    PARAM_TYPE_ERROR = "PARAM_TYPE_ERROR"

    # æƒé™é”™è¯¯
    PERMISSION_DENIED = "PERMISSION_DENIED"
    NOT_IN_WHITELIST = "NOT_IN_WHITELIST"

    # èµ„æºé”™è¯¯
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    FILE_TOO_LARGE = "FILE_TOO_LARGE"
    RESOURCE_BUSY = "RESOURCE_BUSY"

    # æ‰§è¡Œé”™è¯¯
    COMMAND_FAILED = "COMMAND_FAILED"
    COMMAND_TIMEOUT = "COMMAND_TIMEOUT"
    EXECUTION_ERROR = "EXECUTION_ERROR"

    # ç½‘ç»œé”™è¯¯
    NETWORK_ERROR = "NETWORK_ERROR"
    API_ERROR = "API_ERROR"

    # æœªçŸ¥é”™è¯¯
    UNKNOWN_ERROR = "UNKNOWN_ERROR"

class ToolExecutionResult:
    """å·¥å…·æ‰§è¡Œç»“æœï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(
        self,
        success: bool,
        output: str = "",
        error: Optional[str] = None,
        error_type: Optional[ErrorType] = None,
        error_code: Optional[str] = None,
        suggested_fix: Optional[str] = None,
        retry_able: bool = False,
        duration: float = 0.0
    ):
        self.success = success
        self.output = output
        self.error = error
        self.error_type = error_type
        self.error_code = error_code
        self.suggested_fix = suggested_fix  # å»ºè®®çš„ä¿®å¤æ–¹æ¡ˆ
        self.retry_able = retry_able        # æ˜¯å¦å¯é‡è¯•
        self.duration = duration

    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "success": self.success,
            "output": self.output,
            "error": self.error,
            "error_type": self.error_type.value if self.error_type else None,
            "error_code": self.error_code,
            "suggested_fix": self.suggested_fix,
            "retry_able": self.retry_able,
            "duration": self.duration
        }
```

#### å…·ä½“å·¥å…·çš„é”™è¯¯å¤„ç†ç¤ºä¾‹

```python
# src/tools/file_download.py
class FileDownloadTool(Tool):
    """æ–‡ä»¶ä¸‹è½½å‡†å¤‡å·¥å…·ï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""

    def execute(self, file_path: str, transport_mode: str = "auto",
                **kwargs) -> ToolExecutionResult:
        """å‡†å¤‡æ–‡ä»¶ä¸‹è½½ï¼ˆç»“æ„åŒ–é”™è¯¯ï¼‰"""

        # é”™è¯¯1: æ–‡ä»¶è·¯å¾„æœªæä¾›
        if not file_path:
            return ToolExecutionResult(
                success=False,
                error="æ–‡ä»¶è·¯å¾„å‚æ•°ç¼ºå¤±",
                error_type=ErrorType.MISSING_PARAM,
                error_code="MISSING_FILE_PATH",
                suggested_fix=(
                    "è¯·å…ˆä½¿ç”¨ semantic_search å·¥å…·æœç´¢æ–‡ä»¶è·¯å¾„ã€‚"
                    "ä¾‹å¦‚ï¼šsemantic_search(query='config.yaml')"
                ),
                retry_able=True
            )

        # é”™è¯¯2: è·¯å¾„ä¸åœ¨ç™½åå•
        is_valid, error_msg = self.path_validator.is_allowed(file_path)
        if not is_valid:
            return ToolExecutionResult(
                success=False,
                error=f"æ–‡ä»¶è·¯å¾„ä¸åœ¨ç™½åå•ä¸­: {file_path}",
                error_type=ErrorType.NOT_IN_WHITELIST,
                error_code="PATH_NOT_ALLOWED",
                suggested_fix=(
                    f"å…è®¸çš„è·¯å¾„èŒƒå›´: {self.path_validator.ALLOWED_PATHS}ã€‚"
                    f"è¯·ç¡®ä¿æ–‡ä»¶åœ¨å…è®¸çš„è·¯å¾„ä¸‹ã€‚"
                ),
                retry_able=False
            )

        # é”™è¯¯3: æ–‡ä»¶ä¸å­˜åœ¨
        if not os.path.exists(file_path):
            return ToolExecutionResult(
                success=False,
                error=f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                error_type=ErrorType.FILE_NOT_FOUND,
                error_code="FILE_NOT_FOUND",
                suggested_fix=(
                    "è¯·ä½¿ç”¨ semantic_search é‡æ–°æœç´¢æ–‡ä»¶ã€‚"
                    "å¯èƒ½çš„åŸå› ï¼š\n"
                    "1. æ–‡ä»¶å·²è¢«åˆ é™¤\n"
                    "2. æœç´¢ç»“æœä¸­çš„è·¯å¾„å·²è¿‡æœŸ"
                ),
                retry_able=True
            )

        # é”™è¯¯4: æ–‡ä»¶è¿‡å¤§
        file_size = os.path.getsize(file_path)
        max_size = 500 * 1024 * 1024  # 500MB
        if file_size > max_size:
            return ToolExecutionResult(
                success=False,
                error=f"æ–‡ä»¶è¿‡å¤§: {file_size / (1024**2):.1f}MB > {max_size / (1024**2):.1f}MB",
                error_type=ErrorType.FILE_TOO_LARGE,
                error_code="FILE_TOO_LARGE",
                suggested_fix=(
                    f"æ–‡ä»¶å¤§å°è¶…å‡ºé™åˆ¶ã€‚å»ºè®®ï¼š\n"
                    f"1. ä½¿ç”¨å‹ç¼©ä¼ è¾“ï¼ˆå¦‚æœ‰ï¼‰\n"
                    f"2. åˆ†å‰²æ–‡ä»¶ååˆ†åˆ«ä¸‹è½½"
                ),
                retry_able=False
            )

        # æˆåŠŸ
        try:
            download_info = self._prepare_download(file_path, transport_mode)
            return ToolExecutionResult(
                success=True,
                output=json.dumps(download_info, ensure_ascii=False),
                duration=0.10
            )

        except Exception as e:
            return ToolExecutionResult(
                success=False,
                error=f"å‡†å¤‡ä¸‹è½½å¤±è´¥: {str(e)}",
                error_type=ErrorType.EXECUTION_ERROR,
                error_code="DOWNLOAD_PREP_FAILED",
                suggested_fix=(
                    "è¯·é‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚"
                    "å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå¯èƒ½æ˜¯ç³»ç»Ÿé…ç½®é—®é¢˜ã€‚"
                ),
                retry_able=True
            )
```

#### Agentçš„è‡ªæˆ‘ä¿®æ­£é€»è¾‘

```python
# src/server/agent.py
class Agent:
    """ReAct Agentï¼ˆå¢å¼ºé”™è¯¯å¤„ç†ï¼‰"""

    async def _think_and_decide(self, session, user_message: str) -> str:
        """æ€è€ƒå’Œå†³ç­–ï¼ˆæ”¯æŒé”™è¯¯ä¿®æ­£ï¼‰"""

        max_retries = 3
        retry_count = 0

        while retry_count < max_retries:
            # 1. è°ƒç”¨LLMé€‰æ‹©å·¥å…·
            tool_name, args = await self._select_tool(user_message)

            # 2. æ‰§è¡Œå·¥å…·
            result = await self._execute_tool(tool_name, args)

            # 3. æ£€æŸ¥ç»“æœ
            if result.success:
                # æˆåŠŸï¼šè¿”å›ç»“æœ
                return self._format_success_response(result)

            # 4. å¤±è´¥ï¼šåˆ†æé”™è¯¯
            error_response = await self._handle_error(
                result,
                tool_name,
                args,
                retry_count
            )

            # 5. åˆ¤æ–­æ˜¯å¦å¯é‡è¯•
            if result.retry_able and retry_count < max_retries - 1:
                retry_count += 1

                # å‘ç”¨æˆ·è¯´æ˜é‡è¯•
                if retry_count == 1:
                    error_response += f"\n\næ­£åœ¨å°è¯•è‡ªåŠ¨ä¿®æ­£..."

                # æ ¹æ®å»ºè®®ä¿®å¤æ–¹æ¡ˆè°ƒæ•´å‚æ•°
                if result.suggested_fix:
                    # å°†é”™è¯¯ä¿¡æ¯å’Œå»ºè®®åé¦ˆç»™LLMï¼Œè®©å…¶é‡æ–°å†³ç­–
                    user_message = f"""
                    ä¸Šä¸€æ¬¡å°è¯•å¤±è´¥ï¼š
                    å·¥å…·: {tool_name}
                    é”™è¯¯: {result.error}
                    å»ºè®®: {result.suggested_fix}

                    è¯·æ ¹æ®å»ºè®®é‡æ–°æ‰§è¡Œä»»åŠ¡ã€‚
                    """

                continue
            else:
                # ä¸å¯é‡è¯•æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                return error_response

    async def _handle_error(
        self,
        result: ToolExecutionResult,
        tool_name: str,
        args: dict,
        retry_count: int
    ) -> str:
        """å¤„ç†é”™è¯¯ï¼ˆç”Ÿæˆå‹å¥½å“åº”ï¼‰"""

        # æ ¹æ®é”™è¯¯ç±»å‹ç”Ÿæˆä¸åŒçš„å“åº”
        if result.error_type == ErrorType.MISSING_PARAM:
            return (
                f"âŒ ç¼ºå°‘å¿…è¦å‚æ•°: {result.error_code}\n"
                f"ğŸ’¡ å»ºè®®: {result.suggested_fix}"
            )

        elif result.error_type == ErrorType.FILE_NOT_FOUND:
            return (
                f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {args.get('file_path', 'unknown')}\n"
                f"ğŸ’¡ å»ºè®®: {result.suggested_fix}"
            )

        elif result.error_type == ErrorType.NOT_IN_WHITELIST:
            return (
                f"âŒ æƒé™ä¸è¶³: {result.error}\n"
                f"ğŸ’¡ å»ºè®®: {result.suggested_fix}"
            )

        elif result.error_type == ErrorType.COMMAND_TIMEOUT:
            return (
                f"â±ï¸ å‘½ä»¤æ‰§è¡Œè¶…æ—¶\n"
                f"ğŸ’¡ å»ºè®®: {result.suggested_fix}"
            )

        else:
            # é€šç”¨é”™è¯¯
            return (
                f"âŒ æ‰§è¡Œå¤±è´¥: {result.error}\n"
                f"ğŸ’¡ å»ºè®®: {result.suggested_fix or 'è¯·è”ç³»ç®¡ç†å‘˜'}"
            )
```

#### é”™è¯¯å“åº”ç¤ºä¾‹

**åœºæ™¯1ï¼šæ–‡ä»¶è·¯å¾„ç¼ºå¤±**
```
ç”¨æˆ·: "ä¸‹è½½é…ç½®æ–‡ä»¶"
  â†“
Agentå°è¯•: file_download(file_path=None)
  â†“
è¿”å›: {
  "success": false,
  "error_type": "MISSING_PARAM",
  "error": "æ–‡ä»¶è·¯å¾„å‚æ•°ç¼ºå¤±",
  "suggested_fix": "è¯·å…ˆä½¿ç”¨ semantic_search å·¥å…·æœç´¢æ–‡ä»¶è·¯å¾„"
}
  â†“
Agentè‡ªæˆ‘ä¿®æ­£:
  â†“
Step 1: semantic_search(query="é…ç½®æ–‡ä»¶")
  â†’ è¿”å›: {filepath: "/storage/uploads/abc123/config.yaml"}
  â†“
Step 2: file_download(file_path="/storage/uploads/abc123/config.yaml")
  â†’ âœ… æˆåŠŸ
  â†“
æœ€ç»ˆå“åº”: "âœ… é…ç½®æ–‡ä»¶å·²å‡†å¤‡ä¸‹è½½ (RDT token: token_xyz)"
```

**åœºæ™¯2ï¼šæ–‡ä»¶ä¸å­˜åœ¨**
```
ç”¨æˆ·: "ä¸‹è½½ app.log"
  â†“
Agentå°è¯•:
  Step 1: semantic_search(query="app.log")
    â†’ è¿”å›: {filepath: "/storage/uploads/xyz789/app.log"}
  Step 2: file_download(file_path="/storage/uploads/xyz789/app.log")
  â†“
è¿”å›: {
  "success": false,
  "error_type": "FILE_NOT_FOUND",
  "error": "æ–‡ä»¶ä¸å­˜åœ¨: /storage/uploads/xyz789/app.log",
  "suggested_fix": "è¯·ä½¿ç”¨ semantic_search é‡æ–°æœç´¢æ–‡ä»¶ã€‚å¯èƒ½çš„åŸå› ï¼š1. æ–‡ä»¶å·²è¢«åˆ é™¤"
}
  â†“
Agentå“åº”:
  "âŒ æ–‡ä»¶æœªæ‰¾åˆ°: /storage/uploads/xyz789/app.log
  ğŸ’¡ å»ºè®®: è¯·ä½¿ç”¨ semantic_search é‡æ–°æœç´¢æ–‡ä»¶ã€‚
  å¯èƒ½çš„åŸå› ï¼š
  1. æ–‡ä»¶å·²è¢«åˆ é™¤
  2. æœç´¢ç»“æœä¸­çš„è·¯å¾„å·²è¿‡æœŸ

  æ­£åœ¨å°è¯•é‡æ–°æœç´¢..."
  â†“
Agentè‡ªæˆ‘ä¿®æ­£:
  semantic_search(query="app.log", scope="uploads")
  â†’ è¿”å›: {filepath: "/storage/uploads/def456/app.log"}
  â†“
æœ€ç»ˆå“åº”: "âœ… æ‰¾åˆ°æ–°çš„æ—¥å¿—æ–‡ä»¶ï¼Œå·²å‡†å¤‡ä¸‹è½½"
```

---

## å®æ–½ä¼˜å…ˆçº§

### P0ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰- ç«‹å³å®æ–½

1. **æ”¹è¿›2ï¼šæ··åˆæ£€ç´¢ç­–ç•¥**
   - æŠ•å…¥äº§å‡ºæ¯”æœ€é«˜
   - æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒ
   - å®æ–½éš¾åº¦ï¼šä¸­ç­‰
   - é¢„æœŸå·¥ä½œé‡ï¼š4å°æ—¶

### P1ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰- è¿‘æœŸå®æ–½

2. **æ”¹è¿›3ï¼šå‹å¥½é”™è¯¯å¤„ç†**
   - æå‡ç³»ç»Ÿå¯ç”¨æ€§
   - æ”¯æŒè‡ªæˆ‘ä¿®æ­£
   - å®æ–½éš¾åº¦ï¼šä¸­ç­‰
   - é¢„æœŸå·¥ä½œé‡ï¼š6å°æ—¶

### P2ï¼ˆä½ä¼˜å…ˆçº§ï¼‰- æŒ‰éœ€å®æ–½

3. **æ”¹è¿›1ï¼šå¼‚æ­¥å‘½ä»¤æ‰§è¡Œ**
   - ä»…åœ¨éœ€è¦æ‰§è¡Œé•¿å‘½ä»¤æ—¶
   - å¢åŠ å¤æ‚åº¦
   - å®æ–½éš¾åº¦ï¼šè¾ƒé«˜
   - é¢„æœŸå·¥ä½œé‡ï¼š8å°æ—¶

---

## æ€»ç»“

### æ”¹è¿›å¯¹æ¯”

| æ”¹è¿›é¡¹ | å½“å‰é—®é¢˜ | è§£å†³æ–¹æ¡ˆ | ä¼˜å…ˆçº§ | å·¥ä½œé‡ |
|-------|---------|---------|--------|--------|
| æ··åˆæ£€ç´¢ | ç²¾ç¡®æ–‡ä»¶åæ£€ç´¢ä¸å‡†ç¡® | å…³é”®å­—+è¯­ä¹‰æ··åˆç­–ç•¥ | P0 | 4h |
| é”™è¯¯å¤„ç† | å¼‚å¸¸ç›´æ¥æŠ›å‡º | ç»“æ„åŒ–é”™è¯¯+è‡ªæˆ‘ä¿®æ­£ | P1 | 6h |
| å¼‚æ­¥å‘½ä»¤ | é•¿å‘½ä»¤è¶…æ—¶ | å¼‚æ­¥æ‰§è¡Œ+è½®è¯¢ | P2 | 8h |

### é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | å½“å‰ | æ”¹è¿›å | æå‡ |
|------|------|--------|------|
| æ–‡ä»¶æ£€ç´¢å‡†ç¡®ç‡ | 90% | 98% | +8% |
| é”™è¯¯è‡ªæˆ‘ä¿®æ­£ç‡ | 0% | 60% | +60% |
| é•¿å‘½ä»¤æˆåŠŸç‡ | 70% | 95% | +25% |
| ç”¨æˆ·æ»¡æ„åº¦ | 75% | 92% | +17% |

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2025-12-31 08:30:00
**ä¸‹ä¸€æ­¥**: å®æ–½P0æ”¹è¿›ï¼ˆæ··åˆæ£€ç´¢ç­–ç•¥ï¼‰
