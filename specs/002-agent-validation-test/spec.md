# 功能规范: Agent功能全面验证测试

**功能分支**: `002-agent-validation-test`
**创建时间**: 2025-12-29
**状态**: 草案
**输入**: 用户描述: "逐步验证后端已经开发的agent相关功能。需要多种测试样例传给agent，测试需要输出完整的工具链调用和最终结果来分析是否正确实现。全部采用真实的大模型（glm-4-flash)和接口进行测试。每进行一项测试需要生成详细的报告（包括输入，完整的工具链调用，最终结果）供用户参考以判断是否满足功能需求，用户确认通过了再进行下一项测试。"

## 用户场景与测试 *(必填)*

### 用户故事 1 - 基础对话功能验证 (优先级: P1)

用户希望验证Agent的基础对话能力，确保它能够进行正常的问答交流，不需要使用任何工具。

**优先级原因**: 这是Agent最基本的功能，必须首先验证。如果基础对话都无法工作，更复杂的功能就没有意义。

**独立测试**: 可以通过向Agent发送简单的问候和问答，验证Agent是否能够返回合理的回复，完全独立于工具调用功能。

**验收场景**:

1. **给定** Agent已初始化并连接到智谱API，**当** 用户发送问候消息"你好"，**那么** Agent应该返回友好的问候回复，不调用任何工具
2. **给定** Agent已初始化，**当** 用户询问简单问题"你是什么？"，**那么** Agent应该自我介绍，说明它是智能运维助手
3. **给定** Agent已初始化，**当** 用户发送"谢谢"，**那么** Agent应该礼貌回应，不触发工具调用

---

### 用户故事 2 - 系统监控工具验证 (优先级: P1)

用户需要验证Agent正确调用系统监控工具（sys_monitor），获取CPU、内存、磁盘使用情况。

**优先级原因**: 系统监控是Agent的核心工具之一，用于运维场景，必须确保工具调用机制工作正常。

**独立测试**: 通过向Agent询问系统状态相关的问题，验证它能够正确识别需要使用sys_monitor工具，并成功获取系统资源信息。

**验收场景**:

1. **给定** Agent已初始化并配置了sys_monitor工具，**当** 用户询问"查看CPU使用率"，**那么** Agent应该调用sys_monitor工具，参数为{"metric": "cpu"}，并返回CPU使用情况
2. **给定** Agent已配置sys_monitor工具，**当** 用户询问"系统状态如何？"，**那么** Agent应该调用sys_monitor工具获取所有指标（metric: "all"），并返回完整的系统状态信息
3. **给定** Agent已配置sys_monitor工具，**当** 用户询问"内存使用情况"，**那么** Agent应该正确调用工具并返回内存使用率、可用内存等信息

---

### 用户故事 3 - 命令执行工具验证 (优先级: P1)

用户需要验证Agent能够安全地执行系统命令（command_executor），如列出文件、查看文件内容等。

**优先级原因**: 命令执行是Agent的关键功能，用于文件操作和系统管理，必须验证安全性和正确性。

**独立测试**: 通过向Agent请求文件操作任务，验证它能够调用command_executor工具，并正确执行允许的命令（ls, cat, grep等）。

**验收场景**:

1. **给定** Agent已初始化并配置了command_executor工具，**当** 用户询问"列出当前目录文件"，**那么** Agent应该调用command_executor工具，参数为{"command": "ls", "args": ["-la"]}，并返回文件列表
2. **给定** Agent已配置command_executor工具，**当** 用户询问"查看README文件内容"，**那么** Agent应该调用工具执行cat命令，并返回文件内容
3. **给定** Agent已配置command_executor工具，**当** 用户请求执行黑名单命令（如"rm -rf /"），**那么** Agent应该拒绝执行或返回错误提示

---

### 用户故事 4 - 测试报告生成验证 (优先级: P1)

用户需要为每项测试生成详细的报告，包含输入、工具链调用、结果等信息。

**优先级原因**: 测试报告是用户判断功能是否满足需求的依据，必须清晰、完整、可追溯。

**独立测试**: 执行测试后，生成结构化的报告文档，包含所有关键信息。

**验收场景**:

1. **给定** 测试执行完成，**当** 生成测试报告，**那么** 报告应该包含测试编号、测试名称、输入、完整的工具链调用列表、最终结果、执行时间、状态（通过/失败）
2. **给定** 测试报告生成，**当** 工具被调用，**那么** 报告应该记录每个工具的名称、参数、执行结果、状态、执行时间、时间戳
3. **给定** 测试报告生成，**当** 测试失败，**那么** 报告应该明确说明失败原因和错误信息

---

### 用户故事 5 - 多轮工具调用验证 (优先级: P2)

用户需要验证Agent能够在一次对话中进行多轮工具调用，解决复杂问题。

**优先级原因**: 实际运维场景可能需要组合多个工具，这是Agent智能决策能力的体现。

**独立测试**: 通过向Agent提出复杂任务，观察它是否能自主决定调用多个工具，并整合结果。

**验收场景**:

1. **给定** Agent已配置所有工具，**当** 用户请求"检查系统状态并列出当前目录文件"，**那么** Agent应该先调用sys_monitor获取系统状态，然后调用command_executor列出文件，最后整合两个工具的结果给出综合回答
2. **给定** Agent已配置所有工具，**当** 用户请求多步骤任务，**那么** 工具调用次数不应超过最大轮数限制（默认5轮）
3. **给定** Agent已配置所有工具，**当** 某个工具执行失败，**那么** Agent应该能够尝试其他工具或给出合理的错误提示

---

### 用户故事 6 - RAG检索工具验证 (优先级: P2)

用户需要验证Agent能够使用RAG工具（rag_search）在已索引的文件中进行语义检索。

**优先级原因**: RAG功能使Agent能够理解和检索文档内容，是智能助手的进阶能力。

**独立测试**: 通过向Agent询问文档相关的问题，验证它能够调用rag_search工具进行语义检索。

**验收场景**:

1. **给定** Agent已配置rag_search工具且有已索引的文件，**当** 用户询问文档相关问题，**那么** Agent应该调用rag_search工具进行语义检索，并基于检索结果回答
2. **给定** Agent已配置rag_search工具，**当** 用户询问的内容在索引文件中，**那么** Agent应该返回相关的文档片段和引用
3. **给定** Agent已配置rag_search工具，**当** 没有已索引的文件，**那么** Agent应该提示用户先索引文件或说明无法进行检索

---

### 用户故事 7 - 对话上下文验证 (优先级: P2)

用户需要验证Agent能够维护对话历史，理解上下文中的引用。

**优先级原因**: 多轮对话能力使Agent能够理解上下文，提供连贯的交互体验。

**独立测试**: 通过多轮对话验证Agent能够记住之前的对话内容并正确引用。

**验收场景**:

1. **给定** Agent已初始化对话历史，**当** 第一轮对话中用户说"我的名字是张三"，**然后** 第二轮用户问"我叫什么名字？"，**那么** Agent应该基于对话历史回答"张三"
2. **给定** Agent有对话历史，**当** 用户使用代词引用之前的内容（如"它"），**那么** Agent应该能够理解并正确回答
3. **给定** Agent有对话历史，**当** 用户询问之前的工具调用结果，**那么** Agent应该能够回忆并说明

---

### 用户故事 8 - 工具超时和错误处理验证 (优先级: P2)

用户需要验证Agent能够正确处理工具执行超时和错误情况。

**优先级原因**: 实际使用中工具可能失败或超时，Agent必须能够优雅地处理这些异常情况。

**独立测试**: 通过配置超时限制或触发错误场景，验证Agent的错误处理机制。

**验收场景**:

1. **给定** Agent配置了工具超时为5秒，**当** 工具执行时间超过5秒，**那么** Agent应该标记工具调用为超时，并继续后续处理或返回错误提示
2. **给定** Agent已初始化，**当** 调用不存在的工具，**那么** Agent应该识别错误并返回"工具不存在"的提示
3. **给定** Agent已初始化，**当** 工具执行失败（返回error），**那么** Agent应该记录失败状态并尝试其他方法或提示用户

---

### 用户故事 9 - 模型切换功能验证 (优先级: P2)

用户需要验证Agent的模型切换功能，能够在运行时动态切换大模型。

**优先级原因**: 模型切换功能使系统能够根据需求调整模型（如从glm-4-flash切换到glm-4.5-flash），提供灵活性。

**独立测试**: 通过调用模型切换接口，验证模型确实切换成功并生效。

**验收场景**:

1. **给定** Agent初始化使用glm-4-flash模型，**当** 调用set_model切换到glm-4.5-flash，**那么** current_model属性应该更新为"glm-4.5-flash"
2. **给定** Agent已切换模型，**当** 进行后续对话，**那么** 应该使用新模型生成回复
3. **给定** Agent初始化，**当** 尝试切换到不存在的模型，**那么** 应该抛出ValueError并保持当前模型不变

---

### 用户故事 10 - API失败降级验证 (优先级: P3)

用户需要验证当智谱API调用失败时，Agent能够降级到本地工具模式。

**优先级原因**: 降级机制保证了在网络故障或API不可用时，Agent仍能提供基本功能，提高了系统的可用性。

**独立测试**: 通过使用无效的API Key或模拟API失败，验证降级逻辑是否工作。

**验收场景**:

1. **给定** Agent配置了无效的API Key，**当** 用户请求系统监控，**那么** Agent应该降级到本地模式，直接调用sys_monitor工具并返回结果（不经过LLM决策）
2. **给定** Agent在降级模式，**当** API不可用，**那么** Agent应该返回包含"[本地模式]"标记的回复
3. **给定** Agent在降级模式，**当** 用户请求超出本地工具能力的任务，**那么** Agent应该提示API不可用并建议用户检查配置

---

### 边界情况

- 当工具调用次数达到最大轮数限制（默认5轮）时会发生什么？
- 系统如何处理智谱API超时或网络错误？
- 当所有工具都执行失败时，Agent如何响应？
- 当用户发送空消息或无意义消息时，Agent如何处理？
- 当对话历史过长时，Agent如何管理上下文（max_turns=5）？
- 当工具返回空结果或格式错误时，Agent如何处理？
- 当Agent状态更新失败或网络中断时，前端如何处理状态不一致？
- 当Agent状态快速连续变化时（如多轮工具调用），前端如何正确显示状态流？

## 需求 *(必填)*

### 功能需求

- **FR-001**: 测试框架必须能够初始化ReActAgent并配置所需的所有工具（command_executor、sys_monitor、rag_search）
- **FR-002**: 测试必须使用真实的智谱API（glm-4-flash模型），不允许使用mock
- **FR-003**: 每项测试必须生成详细的测试报告，包含测试编号、名称、输入、工具链调用详情、输出结果、执行时间、状态
- **FR-004**: 测试报告必须记录每个工具调用的完整信息：工具名称、参数、结果、状态（success/failed/timeout）、执行时间、时间戳
- **FR-005**: 测试必须验证Agent的工具调用决策机制是否正确（在何时选择哪个工具）
- **FR-006**: 测试必须验证Agent的多轮工具调用能力（ReAct循环）
- **FR-007**: 测试必须验证Agent的工具执行超时处理机制
- **FR-008**: 测试必须验证Agent的错误处理能力（工具不存在、工具执行失败）
- **FR-009**: 测试必须验证Agent的对话上下文管理能力
- **FR-010**: 测试必须验证Agent的模型切换功能
- **FR-011**: 测试必须验证Agent的降级机制（API失败时降级到本地工具）
- **FR-012**: 测试必须按照优先级顺序执行（P1 → P2 → P3）
- **FR-013**: 每项测试完成后必须等待用户确认，用户通过后才能进行下一项测试
- **FR-014**: 测试报告必须以人类可读的格式呈现（Markdown格式）
- **FR-015**: 测试框架必须能够记录性能指标（工具调用响应时间、工具执行时间、总响应时间）
- **FR-015-1**: 测试框架必须能够捕获和验证Agent运行时状态更新（thinking、tool_call、generating），这些状态通过NPLT协议的AGENT_THOUGHT消息类型发送到前端
- **FR-015-2**: 测试报告应包含Agent状态变化的记录，包括状态类型（thinking/tool_call/generating）、时间戳和持续时间，验证状态发送的及时性和准确性

### 章程合规需求 (Constitution Compliance Requirements)

- **FR-016**: 系统必须使用 Python 3.11 运行
- **FR-017**: 系统必须使用 uv 管理虚拟环境和依赖
- **FR-018**: 所有日志必须写入 logs 文件夹，格式为纯文本 (.log)
- **FR-019**: 必须使用 zai-sdk 与智谱 AI 集成
- **FR-020**: 必须在启动前验证智谱 API key 已配置（从环境变量ZHIPU_API_KEY读取）
- **FR-021**: 所有测试必须是真实测试，不允许使用 mock
- **FR-022**: 所有功能实现必须是真实的，不允许虚假实现
- **FR-023**: 所有测试报告、用户回复和文档必须使用中文
- **FR-024**: 测试框架必须在每项测试通过后生成可提交的版本

#### 安全合规需求 (Security Compliance Requirements)

- **FR-025**: 命令执行工具必须使用路径白名单控制（来自config.yaml的file_access.allowed_paths）
- **FR-026**: 路径验证器必须防止路径遍历攻击（如 ../ 规范化）
- **FR-027**: 必须维护命令黑名单以保护敏感操作（如rm、mv、chmod等）
- **FR-028**: RAG工具必须验证文件类型（仅文本文件）和文件大小（默认最大10MB）
- **FR-029**: 命令执行必须限制输出大小（默认最大100KB）
- **FR-030**: 所有工具调用必须记录审计日志

### 关键实体

- **测试用例 (TestCase)**: 代表一个独立的测试场景，包含测试编号、名称、输入、预期结果、实际结果、状态
- **工具调用记录 (ToolCall)**: 记录单次工具调用的详细信息，包含工具名称、参数、执行结果、状态、执行时间、时间戳
- **测试报告 (TestReport)**: 汇总一个或多个测试用例的结果，包含测试摘要、详细的工具链调用、性能指标、通过/失败状态

**注意**: Agent运行时状态（thinking、tool_call、generating）通过NPLT协议的AGENT_THOUGHT消息类型发送到前端，不属于测试框架数据实体。测试需要验证Agent状态发送功能是否正常工作。

## 成功标准 *(必填)*

### 可衡量的结果

- **SC-001**: 所有P1优先级测试（基础对话、系统监控、命令执行、测试报告）100%通过
- **SC-002**: 工具调用响应时间（从用户输入到工具状态显示）90%的情况下 < 2秒
- **SC-003**: 工具执行时间（单个工具运行）100% < 5秒（超时限制）
- **SC-004**: 多轮工具调用场景中，Agent能够正确识别并调用合适的工具的准确率 ≥ 90%
- **SC-005**: 测试报告包含完整信息的覆盖率100%（每个测试都有输入、工具链、结果、时间、状态）
- **SC-006**: Agent在API失败时能够成功降级到本地模式的成功率 ≥ 95%
- **SC-007**: 模型切换功能在有效模型之间的切换成功率100%
- **SC-008**: 对话上下文管理能力测试（理解多轮对话中的引用）准确率 ≥ 85%
- **SC-009**: 错误处理场景（工具不存在、工具执行失败、超时）的优雅处理率100%（不崩溃、有明确提示）
- **SC-010**: 用户对每项测试报告的满意度 ≥ 90%（用户确认通过率）

### 质量标准

- **QS-001**: 所有测试使用真实的智谱API（glm-4-flash），无mock
- **QS-002**: 测试报告结构清晰，信息完整，便于用户判断功能是否满足需求
- **QS-003**: 测试覆盖所有用户故事定义的验收场景
- **QS-004**: 测试按照优先级顺序执行，用户确认驱动测试进度
- **QS-005**: 测试框架易于扩展，便于添加新的测试用例

## 测试执行计划

### 测试分组

**P1组（核心功能）**:
- T001: 基础对话功能验证
- T002: 系统监控工具验证
- T003: 命令执行工具验证
- T004: 测试报告生成验证

**P2组（进阶功能）**:
- T005: 多轮工具调用验证
- T006: RAG检索工具验证
- T007: 对话上下文验证
- T008: 工具超时和错误处理验证
- T009: 模型切换功能验证

**P3组（边缘场景）**:
- T010: API失败降级验证

### 测试执行流程

1. 初始化测试环境（验证API Key、创建Agent实例）
2. 按照优先级顺序执行测试用例
3. 每个测试用例执行后生成详细报告
4. 向用户展示报告并等待确认
5. 用户确认通过后继续下一个测试
6. 用户拒绝时记录失败原因，允许重测或跳过
7. 所有测试完成后生成汇总报告

### 测试报告格式

每个测试报告包含以下章节：

```markdown
# 测试报告 TXXX: [测试名称]

## 测试信息
- 测试编号: TXXX
- 测试名称: [名称]
- 优先级: P1/P2/P3
- 执行时间: [时间戳]
- 状态: ✅ 通过 / ❌ 失败

## 测试输入
用户消息: [用户输入]
对话历史: [如果有上下文]

## 工具链调用详情
### 工具调用 1
- 工具名称: [tool_name]
- 调用时间: [timestamp]
- 参数: {key: value}
- 执行时间: [duration]s
- 状态: success/failed/timeout
- 结果: [output或error]

### 工具调用 2
...

## 最终结果
Agent回复: [最终回复文本]

## 性能指标
- 总响应时间: [time]s
- 工具调用次数: [count]
- 工具执行总时间: [time]s
- 平均工具执行时间: [time]s

## 验收结果
- 场景1: [✅ 通过 / ❌ 失败] - [说明]
- 场景2: [✅ 通过 / ❌ 失败] - [说明]

## 测试结论
[通过/失败的判断依据]
```

## 假设与约束

### 假设

- 用户已配置有效的ZHIPU_API_KEY环境变量
- 测试环境有网络连接，能够访问智谱API
- 测试环境有足够的系统资源（CPU、内存）执行测试
- 用户了解Agent的基本功能，能够判断测试结果是否符合预期

### 约束

- 测试必须使用真实的智谱API，可能产生API调用费用
- 测试执行速度受网络延迟和API响应时间影响
- 某些测试场景（如RAG检索）需要预先准备索引文件
- 测试报告以Markdown格式生成，需要用户使用支持Markdown的工具查看

## 下一步行动

1. 创建测试框架代码结构
2. 实现测试报告生成器
3. 实现P1组测试用例
4. 执行T001（基础对话）并生成报告
5. 等待用户确认后继续T002...
