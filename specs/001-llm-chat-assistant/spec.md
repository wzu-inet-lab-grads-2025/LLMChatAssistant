# 功能规范: 智能网络运维助手

**功能分支**: `001-llm-chat-assistant`
**创建时间**: 2025-12-28
**状态**: 完成
**输入**: 用户描述: "实现智能网络运维助手，包含TCP长连接通信(NPLT协议)、UDP可靠文件传输(RDT协议)和基于智谱AI的Agent工具调用功能"

## Clarifications

### Session 2025-12-28

- Q: LLM 聊天模型默认选择 (glm-4-flash vs glm-4.5-flash) → A: glm-4-flash (成本更低，速度更快)
- Q: 向量数据持久化策略 (内存 vs 磁盘 vs 混合) → A: 持久化到 storage/vectors/ 目录，服务器重启后自动加载，支持增量更新
- Q: 对话历史持久化范围 (多用户会话 vs 单会话 vs 全局) → A: 单用户场景，按会话保存历史到 storage/history/
- Q: LLM Provider 扩展架构 (抽象接口 vs 配置驱动 vs 插件) → A: 抽象接口模式，智谱作为首个实现
- Q: 文件上传大小限制 (1MB vs 10MB vs 100MB) → A: 10MB 限制，平衡资源使用和功能性
- Q: 项目配置文件结构 → A: 使用 config.yaml 存储服务器、LLM、存储、日志配置，敏感信息（API key）存储在 .env 文件中，在 config.yaml 中使用环境变量引用（如 ${ZHIPU_API_KEY}）
- Q: 客户端如何获取服务器连接配置 → A: 客户端使用独立的配置文件，指定服务器地址和端口
- Q: .env 文件中需要哪些环境变量 → A: 仅 ZHIPU_API_KEY（唯一敏感信息）
- Q: 配置加载优先级 → A: 命令行参数 > 环境变量 > config.yaml（环境变量可覆盖配置文件）
- Q: 配置文件放置位置 → A: 项目根目录（与 src/, logs/, storage/ 同级）

### Session 2025-12-29

- Q: 用户故事2验收场景#3文件大小描述 → A: 修正为"大文件（超过1MB）"以与10MB限制保持一致，强调分块处理机制
- Q: 模型切换失败的用户反馈策略 → A: 服务器必须验证模型确实切换成功后才发送确认消息，切换失败时返回错误并保持当前模型（确保客户端状态与服务器实际状态一致）
- Q: 前后端职责划分 → A: 前端仅负责发送消息（聊天消息、/命令+消息、文件等）和接收解码后端回复，并格式化输出显示；后端 Agent 自动化调用 ReAct 循环处理前端消息，通过工具链得到最终结果后发送给前端
- Q: AGENT_THOUGHT 消息发送时机 → A: 智能判断：根据实际任务复杂度合理设计（简单任务可批量发送，复杂任务可实时发送以保持用户体验）。实现建议：工具执行步骤 ≤ 3 步时批量发送，> 3 步时实时发送每一步；当前版本采用实时发送策略，未来可考虑根据任务类型动态调整
- Q: 文件上传后索引时机 → A: 智能判断：根据文件大小决定（小文件立即索引，大文件如超过1MB采用后台异步索引）
- Q: API 失败降级触发条件 → A: 连续3次失败后降级到本地命令执行模式，避免偶发网络抖动误触发
- Q: 降级模式恢复机制 → A: 自动尝试：定时重试 API（后台自动恢复，用户无感知，无需手动干预）
- Q: 降级模式用户通知 → A: 智能判断：必要时提示（在 AI 相关功能时提示用户处于本地模式，避免过度干扰）
- Q: 文件内容上下文注入策略 → A: 上传的文件在消息历史中保留索引信息（文件名、索引时间），Agent根据实际需要判断是否调用RAG检索文件内容作为上下文（按需使用，避免不必要的token消耗）
- Q: Agent不确定性交互模式 → A: 基于置信度阈值的混合模式：置信度超过阈值则自动执行，不超过阈值则返回选项供用户选择，每个选项配简要说明，用户选择后Agent结合上下文继续处理并返回最终结果（未来增强功能）
- Q: 文件引用的智能上下文注入 → A: Agent自动检测对话中的文件名或模糊描述（如"刚才上传的文件"、"前面的文件"），判断是否需要文件内容作为上下文，如果需要则根据对话历史中的索引信息获取文件内容并传递给大模型生成最终结果（无需用户明确请求RAG检索）
- Q: 对话上下文窗口大小策略 → A: 基于token阈值的智能压缩机制：计算上下文token数，根据大模型max_tokens限制达到阈值时触发智能压缩，保留关键信息并控制token消耗
- Q: 上下文压缩策略 → A: 智能评分：重要性排序（根据消息重要性评分压缩，保留高价值消息，相比FIFO提供更好的用户体验）
- Q: 对话历史窗口管理机制 → A: 双层管理机制：本地保存完整对话历史用于/history命令查看，传递给大模型的上下文使用压缩+滑动窗口模式（平衡存储完整性和API效率）
- Q: /history 命令交互流程 → A: 客户端发送 HISTORY_REQUEST 消息到服务器，服务器从当前会话的 conversation_history 中获取最近 20 条消息（get_context(num_messages=20)），格式化为可读文本后通过 CHAT_TEXT 消息返回给客户端显示（不改变会话状态）
- Q: /clear 命令交互流程和状态变更 → A: 客户端发送 CLEAR_REQUEST 消息到服务器，服务器调用 session.conversation_history.clear() 清空内存中的消息列表，然后发送"会话历史已清空"确认消息；客户端收到成功响应后执行 ui.clear() 清空本地显示并重新显示欢迎画面（会话历史被重置为空，下一次 LLM 调用时上下文将为空）
- Q: 多会话切换场景定位 → A: 当前实现为单用户单会话场景（每个 TCP 连接对应一个 Session），不支持在多个会话之间切换；多会话管理（会话列表、创建新会话、切换会话）为未来增强功能
- Q: 上下文窗口管理的当前实现状态 → A: 当前实现使用固定轮数策略（Agent 调用 get_context(max_turns=3) 获取最近 3 轮对话），token 阈值压缩和重要性评分机制为未来增强功能；双层管理机制当前仅部分实现（本地保存完整历史，但传递给 LLM 的上下文未启用压缩）
- Q: 多会话管理需求澄清 → A: 单用户场景但支持多历史会话管理，用户需要能够在不同会话之间切换并继续对话
- Q: 多会话切换的交互方式 → A: 支持创建多个命名会话，通过 /sessions 命令列出所有会话并切换（类似 ChatGPT 侧边栏模式）
- Q: 会话创建和命名方式 → A: 基于对话主题自动生成会话名称（使用 AI 分析前几轮对话生成标题）
- Q: 会话切换时上下文处理策略 → A: 完整切换上下文，但实际加载时仅使用压缩后的上下文和上下文窗口标记（符合双层管理机制）
- Q: 会话列表命令的设计 → A: /sessions 显示所有会话列表，/switch <session_id> 切换会话，/new 创建新会话（三个独立命令，职责清晰）
- Q: 会话删除和归档策略 → A: 支持手动删除（/delete <session_id>）和自动归档（超过 30 天未访问的会话自动归档到 storage/history/archive/）

## 用户场景与测试 *(必填)*

### 用户故事 1 - CLI客户端基础对话 (优先级: P1)

用户启动本地CLI客户端，通过TCP长连接连接到远程服务器，在命令行界面中与AI助手进行实时对话，获得系统状态查询、日志分析等运维帮助。

**优先级原因**: 这是系统的核心功能，提供了用户与AI助手交互的基本通道，是所有其他功能的基础。

**独立测试**: 可以通过启动客户端、建立TCP连接、发送简单文本消息并接收AI回复来完全测试基础的对话能力。

**验收场景**:

1. **给定** 客户端已启动且服务器在线，**当** 用户输入"帮我检查一下服务器内存"，**那么** 系统应调用系统监控工具并返回内存使用情况（如"总内存: 16GB，已使用: 8.5GB (53%)"）
2. **给定** TCP连接已建立，**当** AI执行工具时，**那么** 客户端应实时显示工具执行状态（如"⠙ [Tool: sys_monitor] Reading system metrics..."）
3. **给定** AI返回长文本回复，**当** 回复内容流式传输，**那么** 客户端应实时渲染Markdown格式的响应

---

### 用户故事 2 - 文件上传与RAG检索 (优先级: P2)

用户通过CLI命令上传本地文本文件到服务器，AI助手可以对文件内容进行向量检索和语义搜索，基于文件内容回答用户问题。

**优先级原因**: 文件上传和RAG检索增强了AI的知识能力，使其能够基于用户提供的文档进行精准回答，提升了运维助手实用性。

**独立测试**: 可以通过上传一个配置文件、然后询问文件内容相关问题来测试完整的文件索引和检索流程。

**验收场景**:

1. **给定** 本地存在config.yaml文件，**当** 用户输入"/upload config.yaml"，**那么** 系统应显示上传进度条并确认"文件已发送并建立索引"
2. **给定** 文件已上传并建立向量索引，**当** 用户询问"config.yaml中的数据库配置是什么"，**那么** AI应检索相关内容并给出准确答案
3. **给定** 上传的大文件（超过1MB），**当** 系统计算Embedding，**那么** 文件应被分块处理（每块500字，50字重叠）并每块独立建立向量索引

---

### 用户故事 3 - RDT可靠文件传输 (优先级: P3)

当AI助手判断需要向用户发送文件时（如错误日志），系统通过UDP协议实现可靠的文件传输，使用滑动窗口机制处理丢包和重传，在CLI中可视化传输过程。

**优先级原因**: 可靠文件传输是运维场景的关键能力，允许用户获取服务器上的日志、配置等文件，提升问题排查效率。

**独立测试**: 可以通过请求AI发送一个已知大小的日志文件、接受传输提议、观察UDP传输过程和最终文件完整性来测试RDT协议。

**验收场景**:

1. **给定** 服务器存在error.log文件(2.5MB)，**当** AI决定提供该文件，**那么** 客户端应显示"[?] AI准备发送文件: error.log (2.5MB)"并等待用户确认
2. **给定** 用户输入'y'确认接收，**当** UDP传输开始，**那么** CLI应显示滑动窗口状态（如"[101] [102] [103] [104] [105]"和传输进度条）
3. **给定** 传输过程中发生丢包，**当** 发送方超时未收到ACK，**那么** 系统应自动重传丢失的数据包（单包最多重传10次，超过后中止传输并报告失败，与边界情况#6保持一致）
4. **给定** 传输完成，**当** 所有数据包确认接收，**那么** 本地文件应与服务器文件内容完全一致（通过校验和验证）

---

### 边界情况

- 当网络突然断开时，客户端应显示连接错误并尝试重连（最多3次）
- 当AI工具执行超时（超过5秒），系统应返回错误消息并继续对话
- 当上传的文件超过10MB时，系统应拒绝并提示"文件大小超过10MB限制"
- 当上传的文件不是纯文本格式，系统应拒绝并提示"仅支持纯文本文件"
- 当UDP传输中连续丢包超过10次，系统应中止传输并报告失败
- 当命令中包含黑名单字符（如`;`、`&`、`>`），系统应拒绝执行并返回安全警告
- 当智谱API连续3次调用失败（如配额用尽、网络超时），系统应降级为本地命令执行模式，避免偶发网络抖动误触发
- 当模型切换失败时（如LLM Provider回调未设置或模型名称无效），服务器必须返回错误消息并保持当前模型不变，客户端不应更新本地模型状态
- 当尝试切换到不存在的会话ID时，系统应返回错误提示并列出可用会话
- 当删除会话时，系统应要求用户二次确认（除非会话为空）
- 当所有会话都被删除时，系统应自动创建一个默认会话

## 需求 *(必填)*

### 功能需求

- **FR-001**: 客户端必须通过TCP协议与服务器建立长连接，默认端口9999，客户端从独立的配置文件读取服务器地址和端口
- **FR-002**: 客户端必须使用Rich库实现类IDE的沉浸式终端界面，包括启动画面、Spinner动画、Markdown渲染
- **FR-003**: 系统必须实现NPLT协议用于TCP通信，支持消息类型：CHAT_TEXT(0x01)、AGENT_THOUGHT(0x0A)、DOWNLOAD_OFFER(0x0C)
- **FR-004**: 服务器端Agent必须实现ReAct循环，自动化处理所有前端消息（无需前端触发），通过工具链得到结果后返回最终回复，支持最多5轮工具调用（达到5轮后强制停止并返回错误提示，避免无限循环，可通过配置调整轮数限制）
- **FR-004a**: 前后端职责必须明确分离：前端仅负责发送消息（聊天消息、/命令+消息、文件等）和接收解码后端回复，并格式化输出显示；后端负责自动化 Agent 处理、工具调用和结果生成
- **FR-005**: 系统必须提供安全命令执行工具，支持白名单命令（ls、cat、grep、head、tail、ps、pwd、whoami、df、free）
- **FR-006**: 系统必须提供系统监控工具，返回结构化的CPU、内存、磁盘使用数据
- **FR-007**: 系统必须实现RAG检索功能，对上传文件计算Embedding并持久化存储在 storage/vectors/ 目录，支持服务器重启后自动加载（注：当前版本支持全量重建索引，增量更新为未来增强功能）
- **FR-008**: 系统必须创建 storage 目录结构，包括 storage/vectors/ (向量数据)、storage/history/ (对话历史)、storage/uploads/ (上传文件)
- **FR-009**: 系统必须持久化单用户的对话历史到 storage/history/ 目录，支持跨会话的上下文延续和历史查询
- **FR-009a**: 系统必须支持多会话管理功能，允许用户创建、查看、切换和删除多个命名会话 (优先级: P1 扩展)
- **FR-009b**: 系统必须为每个会话自动生成基于对话主题的名称（使用 AI 分析前几轮对话生成标题）(优先级: P1 扩展)
- **FR-009c**: 系统必须支持 /sessions、/switch `<session_id>`、/new、/delete `<session_id>` 命令用于多会话管理 (优先级: P1 扩展)
- **FR-009d**: 会话切换时必须加载完整的压缩上下文和上下文窗口标记（符合双层管理机制）(优先级: P1 扩展)
- **FR-009e**: 系统必须支持会话自动归档功能（超过 30 天未访问的会话自动归档到 storage/history/archive/）(优先级: P1 扩展)
- **FR-010**: 系统必须通过UDP协议实现RDT可靠文件传输，使用滑动窗口机制（窗口大小N=5）
- **FR-011**: 客户端必须支持/upload命令上传纯文本文件，文件大小限制为10MB，显示实时进度条
- **FR-012**: 系统必须在UDP传输中实现超时重传机制，仅对SendBase包计时
- **FR-013**: 客户端必须在RDT传输中可视化显示窗口状态、传输进度、速度和重传统计
- **FR-014**: 系统必须实现TCP心跳机制，间隔90秒保持连接活跃
- **FR-014a**: 系统必须使用 config.yaml 作为主配置文件，包含服务器配置（host、port）、LLM配置（model、temperature）、存储路径（storage_dir、logs_dir）和日志级别
- **FR-014b**: 系统必须从 .env 文件读取 ZHIPU_API_KEY（唯一的敏感环境变量），config.yaml 中使用环境变量引用语法（${ZHIPU_API_KEY}）
- **FR-014c**: 系统必须在启动时验证 config.yaml 存在且格式正确，缺失 .env 时给出明确错误提示（配置验证，在 T020 中实现）
- **FR-014d**: 系统必须支持配置优先级：命令行参数 > 环境变量 > config.yaml，允许环境变量覆盖配置文件中的设置（配置加载优先级，在 T020 中实现）
- **FR-014e**: 配置文件 config.yaml 和 .env 必须放置在项目根目录（与 src/, logs/, storage/ 同级），系统启动时从当前工作目录读取

### 章程合规需求 (Constitution Compliance Requirements)

- **FR-015**: 系统必须使用 Python 3.11 运行
- **FR-016**: 系统必须使用 uv 管理虚拟环境和依赖
- **FR-017**: 所有日志必须写入 logs 文件夹，格式为纯文本 (.log)
- **FR-018**: 系统必须定义统一的 LLM Provider 抽象接口，包含聊天、嵌入等方法，智谱作为第一个实现，方便后续扩展 OpenAI、Claude 等其他 provider
- **FR-019**: 系统必须使用 zai-sdk 与智谱 AI 集成，默认使用 glm-4-flash 模型，支持 glm-4.5-flash 作为可切换选项，向量嵌入使用 embedding-3-pro 模型
- **FR-020**: CLI 必须提供模型切换命令，允许用户在 glm-4-flash 和 glm-4.5-flash 之间动态切换，服务器必须验证模型确实切换成功后才发送确认消息，切换失败时返回错误并保持当前模型
- **FR-021**: 系统必须在启动前验证智谱 API key 已配置
- **FR-022**: 所有测试必须是真实测试，不允许使用 mock
- **FR-023**: 所有功能实现必须是真实的，不允许虚假实现
- **FR-024**: 所有用户回复、注释和文档必须使用中文
- **FR-025**: 错误消息、日志输出必须使用中文

### 系统架构

**架构模型**: 单用户多会话架构

本系统采用单用户多会话架构模型：

- **单用户**: 每个服务器实例支持一个用户场景（未来扩展目标为支持多用户并发）
- **多会话**: 单个用户可以创建多个命名会话，每个会话独立维护对话历史和上下文
- **会话隔离**: 不同会话之间完全隔离，切换会话时加载对应的压缩上下文
- **会话管理**: 支持会话创建、查看、切换、删除、自动命名和自动归档功能（FR-009a 到 FR-009e）

### 关键实体

- **NPLT消息**: TCP应用层协议数据包，包含Type(1B)、Seq(2B)、Len(1B)字段，最大负载255字节
- **RDT数据包**: UDP可靠传输数据包，包含Seq(2B)、Check(2B)、Data(最大1024B)
- **Agent会话**: 用户与AI的对话上下文（支持多会话），每个会话包含历史消息和工具调用结果，持久化到 storage/history/ 目录，支持多会话管理和上下文延续
- **向量索引**: 上传文件的文本块及其Embedding向量，持久化存储在 storage/vectors/ 目录用于语义检索，服务器启动时自动加载
- **下载令牌**: 文件传输的唯一标识，用于关联TCP下载提议和UDP传输通道

## 成功标准 *(必填)*

### 可衡量的结果

- **SC-001**: 用户可以在10秒内启动客户端并建立TCP连接到服务器
- **SC-002**: AI工具调用响应时间（从用户输入到工具状态显示）小于2秒
- **SC-003**: 流式文本响应的延迟（首字到达时间）小于1秒
- **SC-004**: UDP文件传输在0%丢包网络下吞吐量达到1MB/s以上
- **SC-005**: UDP文件传输在10%丢包网络下成功率达到100%（通过重传机制）
- **SC-006**: RAG检索返回的相关文档与用户查询的语义相关性（人工评估）达到80%以上
- **SC-007**: 系统架构支持扩展到多客户端场景（当前实现为单用户场景，未来扩展目标为 10 个并发客户端）。架构设计要点：无状态服务器设计（会话状态持久化到存储层）、异步 I/O 处理（asyncio 支持高并发）、会话隔离机制（每个 TCP 连接对应独立的会话上下文）
- **SC-008**: 客户端UI在长对话（超过100轮）后仍保持流畅（无明显卡顿或内存泄漏）

### 协议设计完整性

- **SC-009**: NPLT协议规范文档包含完整的消息格式表格、状态机图和错误处理流程
- **SC-010**: RDT协议规范文档包含发送方/接收方状态转移图、窗口机制说明和超时重传逻辑
- **SC-011**: 使用Wireshark抓包验证TCP和UDP数据包格式与规范文档一致

### 测试覆盖

- **SC-012**: 测试用例覆盖正常流程、边界条件（大文件传输、高并发）和异常场景（网络断开、丢包、命令注入）
- **SC-013**: 所有核心功能（对话、文件上传、RDT传输）都有对应的自动化测试脚本
